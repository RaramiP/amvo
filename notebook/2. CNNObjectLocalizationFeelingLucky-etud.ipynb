{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36a251ed",
   "metadata": {},
   "source": [
    "# Exercice 2. Detection d'objets en tentant sa chance ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a31a8ad-8de9-48ce-bc7e-31b89ebe3e5a",
   "metadata": {},
   "source": [
    "Dans cette partie, nous allons générer aléatoirement une série de régions. Pour chaque région, nous envisagerons de la faire passer par le classificateur d'objets entraîné (mono- ou multi-catégories) dans l'exercice **1**. Il n'est pas nécessaire de réentraîner le réseau. Effectuez simplement une prediction de la présence ou l'absence d'un objet dans la regions.\n",
    "\n",
    "Lors de la génération aléatoire des régions, vous pouvez demander la génération de plusieurs types de regions (rectangles debouts, carrés, rectangles couchés). Vous obtiendrez ainsi pour chaque image un ensemble de regions caractérisées par: (x<sub>i</sub>,y<sub>i</sub>,w<sub>i</sub>,h<sub>i</sub>).\n",
    "\n",
    "**Q1** Ecrire le code de la function qui génére les regions candidates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95215a33-e3bf-45d2-bc3f-045a00d6c2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateRegions(image,nb_regions):\n",
    "    \n",
    "    return #[[x0,y0,w0,h0],....,[xnr,ynr,wnr,hnr]] - nr=nb_regions and all coordinates are valid within the image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87126429-5237-4313-96c7-54017d4886e1",
   "metadata": {},
   "source": [
    "Vous passerez chacune de ces regions par le réseau (de l'exercice **1**) et vous conserverez uniquement celles pour lesquelles un objet a été reconnu.\n",
    "\n",
    "Conserver la classe et la valeur du logit correspondant qui nous servira à évaluer la confiance en la detection. Ainsi, pour chaque image vous avez une nouvelle description des regions (x<sub>i</sub>,y<sub>i</sub>,w<sub>i</sub>,h<sub>i</sub>,c<sub>i</sub>,logit<sub>i</sub>) où c<sub>i</sub> correspond à la classe et logit<sub>i</sub> au logit ayant déterminé la classe (il jouera le rôle de la confiance qu'on fait en la detection).\n",
    "\n",
    "**Q2** Ecrire le code de la fonction qui preselectionne les régions contenant un objet potentiel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4be0c29-4f04-4cfd-9af8-3bd4aab58cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preselectRegions(image,regions,classifier):\n",
    "    ...\n",
    "    return ... #[[x0,y0,w0,h0,c0,logit0],....,[xns,yns,wns,hns,cns,logitns]] - ns=nb of regions potentially containing an object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e69b5a-cf4a-4c04-8de3-f8acb5a2251e",
   "metadata": {},
   "source": [
    "Pour les régions classées comme contenant un objet, appliquez l'algorithme de suppression des non-maxima classe par classe.\n",
    "\n",
    "Triez les régions par ordre décroissant de score de confiance/prédiction.\n",
    "\n",
    "Calculez l'IoU entre la première région de la liste et toutes les autres. Si l'IoU est supérieur au seuil, supprimez la région correspondante de la liste.\n",
    "\n",
    "Répétez l'opération jusqu'à ce que toutes les régions aient été traitées ou supprimées.\n",
    "\n",
    "**Q3** Proposez une implementation pour le calcul de l'IoU et pour l'algorithm de NonMaxSuppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ffbb94-9475-4d11-99f3-2c2b49980cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(regionA, regionB):\n",
    "    ...\n",
    "    return iou\n",
    "    \n",
    "def nonmaxSuppression(image,classes,regionsWithClassAndLogit):\n",
    "    ...\n",
    "    return ... #[[x0,y0,w0,h0,c0,logit0],....,[xm,ym,wm,hm,cm,logitm]] - m=nb of regions after nonmaxSuppression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16e50c7-cd95-4bd1-aae5-b2aeebd07eeb",
   "metadata": {},
   "source": [
    "**Q4** Calculez ensuite, pour chaque région restante, l'IoU avec les boîtes englobantes consituant la vérité de terrain et gardez uniquement les fenetre avec un IoU supperieur à un seuil fixé. Parcourez les regions en fonction des leur niveau de confiance. Au fur et à mesure que les groundtruth_regions se voient attribuer une candidate_region, il faut enlever cette groundtruth_region de la liste afin d'éviter que plusieurs regions candidates soient ratachées à la même région de la groundtruth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10c13cd-b0e1-4915-98bc-92d6214281c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareToGroundTruth(image,groundtruth_regions,candidate_regions):\n",
    "    ...\n",
    "    return ... # (TPRegions, FNDetected, FNNonDetected)\n",
    "    # where TPRegions - corresponds to the subset of candidate_regions that were matched against the good gt_regions\n",
    "    #       FNDetected - corresponds to the subset of candidate_regions that were not matched against any gt_regions\n",
    "    #       FNNonDetected - corresponds to the subset of groundtruth_regions that were not matched against any candidate_regions\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1a4559-567c-4aa0-a503-38418e5c601a",
   "metadata": {},
   "source": [
    "## Détection d'une classe d'objets\n",
    "\n",
    "Appliquez la procédure à l'ensemble d'images contenant l'étiquette 4 (Éléphant). \n",
    "Nous ne découperons plus par rapport à l'éléphant, mais considérons l'image dans son ensemble. \n",
    "Dans cette situation, nous considérons que tout autre objet apparaîssant sur les images que l'éléphant fait partie de l'arrière plan. \n",
    "Lors du chargement des données, uniquement les regions concernant l'éléphant feront partie de la vérité de terrain.\n",
    "\n",
    "Utilisez un classifier binaire capable de reconnaître un éléphant.\n",
    "\n",
    "Vous devez coder une nouvelle version de la fonction `load_elephant_objects` afin de prendre en compte ces considérations.\n",
    "\n",
    "**Q5** Coder `load_elephant_objects`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3796ee3d-3cf7-4103-90ca-3a331bd1e7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_elephant_objects():\n",
    "    ...\n",
    "    return x,y #x ensemble d'images contenant des éléphants, y ensemble de positions des boîtes englobantes\n",
    "    #attention x=[img1,img1,img1,...], y=[[r11,r12],[r21],[r21,r22,r23],...] \n",
    "    #si l'img1 contient deux éléphants situés à r11 et r12\n",
    "    #si l'img2 contient un seul éléphant\n",
    "    #si l'img3 contient trois eléphants\n",
    "    #rij = [xij,yij,wij,hij]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dca53d-dccb-4dbb-8ccb-e08cb50d2a5c",
   "metadata": {},
   "source": [
    "**Q6** Pour chaque image du test set affichez le nombre de TP, FP, TN.\n",
    "Choissisez un sous-ensemble de 3 images sur lesquelles vous superposer en vert la GT, en blue les TP, en orange les FP et en rouge les FN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bfcb85-409f-4859-ae7d-d1ddafaf34af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14ae1800-2838-4944-b6dc-b0c6bb18fb46",
   "metadata": {},
   "source": [
    "**Q7** Calculez la précision moyenne (AP) pour les images relevant de cette étiquette sur le test set pour un IoU de 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de54487b-5657-4e75-88c6-414f4c068830",
   "metadata": {},
   "source": [
    "Afin de calculer la précision moyenne, il est nécessaire de traiter l'ensemble des detections dans leur globalité par rapport à leur niveau de confiance.\n",
    "\n",
    "Regroupez dans une liste l'ensemble de regions candidates issues de **Q4** tout en conservant une information relative à leur appartenance aux ensembles TPregions ou FPregions. Triez cette liste en fonction de niveau de confiance et parcourez la de manière décroissante.\n",
    "\n",
    "Initialement le rappel est à zero car TP=0, FP=0 et FN=#total regions issues de la **Q4**\n",
    "Au fur et à mesure qu'on traite des regions de la liste on met à jour les valeurs cumulées TP et FP pour calculer la précion et le rappel à chaque nouvelle detection.\n",
    "\n",
    "Tracez un graphique des points (précision, rappel) intermediaires.\n",
    "\n",
    "Vous pouvez utiliser la fonction `sklearn.metrics.auc` pour calculer la valeur d'AUC en fournissant les listes avec les valeurs intermediaires de (précision et rappel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21464318-4827-4447-8e12-7284d116c232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0811335c-6c64-43f7-beaa-67cb3d0ec344",
   "metadata": {},
   "source": [
    "## Détection de plusieurs classes\n",
    "\n",
    "Appliquez la procédure à l'ensemble d'images du dataset. \n",
    "Lors du chargement des données, l'ensemble des regions concernant des objets feront partie de la vérité de terrain. Cette fois-ci l'on gardera également des informations sur la classe spécifique associée à une boîte englobante.\n",
    "\n",
    "**Q7** Vous devez coder une nouvelle version de la fonction `load_objects` afin de prendre en compte ces considérations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5d3de31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_elephant_objects():\n",
    "    ...\n",
    "    return x,y #x ensemble d'images contenant des éléphants, y ensemble de positions des boîtes englobantes\n",
    "    #attention x=[img1,img1,img1,...], y=[[r11,r12],[r21],[r21,r22,r23],...] \n",
    "    #si l'img1 contient deux objets situés à r11 et r12\n",
    "    #si l'img2 contient un seul objet\n",
    "    #si l'img3 contient trois objets\n",
    "    #rij = [xij,yij,wij,hij,cij] où cij correspond à la classe de l'objet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907e6961-4fdd-4a98-846c-7eba98416c3d",
   "metadata": {},
   "source": [
    "**Q8** Calculez la précision moyenne (AP) pour l'ensemble de données pour un IoU de 0.5.\n",
    "Par rapport au cas mono-classe, il est d'usage de calculer l'AUC classe par classe (et donc considerer les régions classe par classe) avant de calculer une moyenne qui tient compte de nombre d'instance de chaque classe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57eea60",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b42ff398",
   "metadata": {},
   "source": [
    "\n",
    "**Q9** (optionnel) Pour guider mieux le processus de génération de regions candidates, vous pouvez également orienter le processus aléatoire en considérant les régions de l'image où se trouvent beaucoup de points caractéristiques (Harris, SIFTs, etc.).\n",
    "Est-ce que cela améliore les résultats ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcf412a-bd20-4451-ac2b-44a801e4358b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
