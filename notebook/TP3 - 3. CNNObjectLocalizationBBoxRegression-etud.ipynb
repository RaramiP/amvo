{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36a251ed",
   "metadata": {},
   "source": [
    "# Exercice 3. [OPTIONNEL] Detection d'objet par regression de boîte englobante "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5afb6d",
   "metadata": {},
   "source": [
    "Dans cette partie, nous aborderons la détection par régression de la boîte englobante.\n",
    "\n",
    "L'échantillon d'entrée n'est plus l'image recadrée, mais l'image entière.\n",
    "\n",
    "L'étiquette ne correspond plus uniquement à la classe de l'objet, mais à sa classe plus sa position dans l'image. \n",
    "Nous allons normaliser cette position dans l'intervalle [0..1] par rapport à la taille de l'image.\n",
    "\n",
    "Pour les premières expériences, nous ne considérerons que les instances de la classe __éléphant__. Par conséquent, nous ne traiterons que les images contenant des éléphants et nous ne conserverons que la première instance au sein de l'image.\n",
    "\n",
    "Pour chaque instance d'elephant nous effectuerons plusieurs découpages autour de l'objet afin d'augmenter le nombre de données disponibles pour l'apprentissage, mais également pour travailler sur des données où l'objet occupe une place importante dans l'image. Cela permettra de simuler le travail au niveau d'une cellule dans une grande image.\n",
    "\n",
    "La fonction ci-dessous permet de prendre en compte cette particularité.\n",
    "\n",
    "**Q1** [Optionnel] Vous pourriez la modifier pour eventuellement ajouter du bruit gaussian autour de l'objet à detecter pour flouter davantage les éléments non pertinent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d3de31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "train_path=\"../tp/tp3/toy-dataset/train/\"\n",
    "\n",
    "def load_instances_of_one_class(imgs_path,label,max_samples=np.iinfo(np.int32),W=128,H=128,samples_per_instance=1):\n",
    "    y_obj=[]\n",
    "    x_obj=[]\n",
    "    imgs_files = os.listdir( imgs_path+\"images/\" )\n",
    "    for i,img_file in enumerate(imgs_files):\n",
    "        if (len(x_obj)==max_samples):\n",
    "            break\n",
    "        \n",
    "        label_file=img_file[:-4]+\".txt\"\n",
    "        labels=csv.reader(open(imgs_path+\"labels/\"+label_file,\"r\"),delimiter=' ')    \n",
    "        img_init=cv2.imread(imgs_path+\"images/\"+img_file)\n",
    "        rows = list(labels)\n",
    "        if len(rows)>0:\n",
    "            for j,row in enumerate(rows):\n",
    "                if (int(row[0]) != label):\n",
    "                    continue\n",
    "            \n",
    "                bbox=np.array(row[1:],dtype=np.float32) if row[0]==1 else np.array(row[1:],dtype=np.float32)\n",
    "                w=int(bbox[2]*img_init.shape[0]*2)\n",
    "                h=int(bbox[3]*img_init.shape[1]*2)\n",
    "                \n",
    "                #should the annotation be out of screen, correct x0,y0,x1,y1\n",
    "                x0=max(0,int(math.trunc(bbox[0]*img_init.shape[0]-w/2)))\n",
    "                y0=max(0,int(math.trunc(bbox[1]*img_init.shape[1]-h/2)))\n",
    "                x1=min(img_init.shape[0],int(math.trunc(x0+w)))\n",
    "                y1=min(img_init.shape[1],int(math.trunc(y0+h)))\n",
    "                h=y1-y0\n",
    "                w=x1-x0\n",
    "                #cv2.rectangle(img_init,(x0,y0),(x0+w,y0+h),4) # to check that we conserve well the initial annotations\n",
    "                \n",
    "                if (H-h<=5 or W-w<=5): # not to much space to randomly crop\n",
    "                    #print(\"skipping due to the initial important size of the object in the image\")\n",
    "                    continue\n",
    "\n",
    "                for s in range(samples_per_instance):\n",
    "                    if (len(x_obj)==max_samples):\n",
    "                        break\n",
    "                        \n",
    "                    startx=x0-W+w if x0-W+w>0 else 0\n",
    "                    endx=x0\n",
    "                    starty=y0-W+w if y0-W+w>0 else 0\n",
    "                    endy=y0\n",
    "                    \n",
    "                    x_crop=random.randint(startx,endx)\n",
    "                    y_crop=random.randint(starty,endy)\n",
    "                    \n",
    "                    x1=min(img_init.shape[0],int(math.trunc(x_crop+W)))\n",
    "                    y1=min(img_init.shape[1],int(math.trunc(y_crop+H)))\n",
    "                    \n",
    "                    if (x1-x_crop != W or y1-y_crop != H):\n",
    "                        continue\n",
    "                    x_obj.append(np.copy(img_init[y_crop:y1,x_crop:x1]))\n",
    "                    y_obj.append([row[0],x0-x_crop,y0-y_crop,x0-x_crop+w,y0-y_crop+h])\n",
    "                    \n",
    "    return x_obj,y_obj\n",
    "\n",
    "def layout_images(images, n_rows=None, n_cols=None, border_size=2):\n",
    "    height, width, n_channels = images[0].shape\n",
    "    height, width = height + border_size, width + border_size\n",
    "    if n_cols is None or n_rows is None:\n",
    "        n_cols = int(np.sqrt(len(images)))\n",
    "        if n_cols**2 < len(images):\n",
    "            n_cols += 1\n",
    "        n_rows = n_cols\n",
    "    output_img = np.zeros((n_rows*height+border_size, n_cols*width+border_size, n_channels), dtype=images[0].dtype)\n",
    "    for i, p in enumerate(images):\n",
    "        r, c = i//n_cols, i%n_cols\n",
    "        output_img[border_size+r*height:(r+1)*height, border_size+c*width:(c+1)*width] = p\n",
    "    return output_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daba804-015e-406a-b376-5ad52e1d14aa",
   "metadata": {},
   "source": [
    "Vous pouvez visualiser quelques instances avec le code ci-dessous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d17bdc4-f463-4216-9833-4b9dc3278681",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_elephant=4\n",
    "label_start=label_elephant\n",
    "label_end=label_elephant+1\n",
    "nb_instances=36\n",
    "nb_samples_par_instance=9\n",
    "nb_cols=9\n",
    "\n",
    "for i in range(label_start,label_end):\n",
    "    x,y=load_instances_of_one_class(train_path,i,nb_instances,128,128,nb_samples_par_instance)\n",
    "    for j in range(nb_instances):\n",
    "        cv2.rectangle(x[j],(y[j][1],y[j][2]),(y[j][3],y[j][4]),5)\n",
    "    plt.imshow(layout_images(x[:nb_instances],int(nb_instances/nb_cols)+1,nb_cols))\n",
    "    plt.pause(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef78cb3",
   "metadata": {},
   "source": [
    "Nous devons maintenant construire le réseau pour la régression des boîtes englobantes. Nous pouvons partir de la structure du réseau utilisée dans l'exercice **1** et modifier la dernière couche dense afin de prédire : les quatre coordonnées de la boîte englobante.\n",
    "Nous présenterons uniquement des images contenant un éléphant, ainsi il n'est pas nécessaire de garder l'information de la présence ou de l'absence de l'objet.\n",
    "\n",
    "La loss sera donc constituée uniquement par la MeanSquaredError.\n",
    "\n",
    "**Q2** Proposez dans un premier temps une architecture simple (quelques couches de convolutions, pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0292470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b42ff398",
   "metadata": {},
   "source": [
    "**Q3** Evaluez la performance en termes de MSE sur l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d4de00-78e0-423f-afac-c1bb929dd075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66028a42-c5c0-4550-856b-cee8a5a5393b",
   "metadata": {},
   "source": [
    "**Q4** Considerons qu'une détection est correcte si on observe un IoU suppérieur à 0.5.\n",
    "\n",
    "Evaluez l'accuracy et le rappel sur l'ensemble de test.\n",
    "\n",
    "Illustrez quelques examples de TP et FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd059c00-9f51-4c26-90e4-3433afb93b87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
